
import com.aslick.strm._
import com.aslick.strm.DynamicLauncher._
import com.aslick.strm.Model.JValueOps
import com.aslick.strm.BaseCryptoCodec.{protect, unprotect}
import com.aslick.strm.Model.{jsonCompactRender, jsonProtect, jsonUnprotect, xmlProtect, xmlUnprotect}
import com.aslick.strm.factory.FrameFactory.{FrameHouse, FrameHouseExecutor}


import java.io.File
import java.nio.file._
import java.nio.charset.{Charset, StandardCharsets}
import java.time.LocalDateTime

import akka.Done
import akka.actor.ActorSystem
import akka.stream.alpakka.slick.javadsl.SlickSession
import akka.stream.alpakka.slick.scaladsl._
import akka.stream.scaladsl._
import akka.stream.IOResult
import akka.util.ByteString
import akka.stream.alpakka.csv.scaladsl.{CsvParsing, CsvToMap, CsvFormatting, CsvQuotingStyle}

import org.slf4j.LoggerFactory


import scala.concurrent.duration._
import scala.concurrent.{Await, ExecutionContext, Future}
import scala.reflect.runtime.universe
import scala.tools.reflect.ToolBox
import scala.util.{Failure, Success}

import slick.collection.heterogeneous.{HCons, HList, HNil}
import slick.jdbc.GetResult
import slick.jdbc.H2Profile.api._


//
//
//
class FileDBExecutor(frameHouse: FrameHouse) extends FrameHouseExecutor(frameHouse) {

  val logger = LoggerFactory.getLogger(getClass)

  //
  val srcFileName = frameHouse.getSourceReader()
  val flowGroupSize = frameHouse.getBatchSize()
  val flowAsyncCount = frameHouse.getParallelismCount()
  val sinkTableName = frameHouse.getSinkWriter()
  val sinkDelete = frameHouse.isSinkDelete()
  val sinkDeleteString = frameHouse.getSinkDelete()
  val sinkCreate = frameHouse.isSinkCreate()
  val sinkCreateString = frameHouse.getSinkCreate()


  //
  case class SourceFrame(${srcCaseString})

  def mapSourceColumns(m: Map[String, String]): SourceFrame = {
    ${srcMapFieldsStr}
  }


  case class SinkFrame(${sinkCaseString})

  class SinkFrames(tag: Tag) extends Table[SinkFrame](tag, sinkTableName) {
    ${sinkFmtClsFields}
  }

  val dropSinkFrame = sqlu" drop table if exists ${sinkTableName}"
  val createSinkFrame = sqlu" ${sinkCreateString}"

  if(sinkDelete) Await.result(sinkSession.db.run(dropSinkFrame), 10.seconds)
  if(sinkCreate) Await.result(sinkSession.db.run(createSinkFrame), 10.seconds)

  val sinkTable = TableQuery[SinkFrames]

  def mapSourceSinkColumns(s: SourceFrame): SinkFrame = {
    ${sinkMapSourceString}
  }

  /**
    * Executes the pipeline
    */
  override def execute(): Unit = {
    //
    println("FileDBExecutor: execute() invoked.")
    println(LocalDateTime.now().toString)

    println(s"Batch Size: ${frameHouse.getBatchSize} Parallelism: ${frameHouse.getParallelismCount}")
    println(sinkCreateString)

    implicit val session = srcSession

    // Stream the results of a query
    val done: Future[Done] =
        FileIO.fromPath(Paths.get(srcFileName))
          .via(${srcFlow})
          .via(CsvToMap.toMapAsStrings(StandardCharsets.UTF_8))
          .map(m => mapSourceColumns(m))
          .map(s => mapSourceSinkColumns(s))
          .grouped(flowGroupSize)
          .mapAsync(flowAsyncCount)( (group: Seq[SinkFrame]) => sinkSession.db.run(sinkTable ++= group).map(_.getOrElse(0)))
          .runWith(Sink.foreach(println))

    //
    done.failed.foreach(exception => logger.error("failure", exception))
    done.onComplete(_ => {
      println(LocalDateTime.now().toString)
      val r = for (c <- sinkTable) yield c
      val b = r.filter(_.id === 41980).result
      val g: Future[Seq[SinkFrame]] = sinkSession.db.run(b)

      g.onComplete {
        case Success(s) => println(s"Result: $s")
        case Failure(t) => t.printStackTrace()
      }
    })

    //
    terminationWait(10.seconds)
    println(LocalDateTime.now().toString)

    println("FileDBExecutor: execute() completed successfully.")
  }

}
scala.reflect.classTag[FileDBExecutor].runtimeClass
